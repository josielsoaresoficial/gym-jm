import { useState, useEffect, useRef, useCallback } from 'react';

export type VoiceRecognitionStatus = 'idle' | 'listening' | 'processing' | 'error' | 'unsupported';

interface VoiceRecognitionState {
  status: VoiceRecognitionStatus;
  transcript: string;
  interimTranscript: string;
  confidence: number;
  audioLevel: number;
  error: string | null;
  isSupported: boolean;
}

interface UseVoiceRecognitionOptions {
  language?: string;
  continuous?: boolean;
  silenceTimeout?: number;
  onResult?: (transcript: string, confidence: number) => void;
  onError?: (error: string) => void;
  enabled?: boolean;
}

export const useVoiceRecognition = ({
  language = 'pt-BR',
  continuous = true,
  silenceTimeout = 2000,
  onResult,
  onError,
  enabled = true
}: UseVoiceRecognitionOptions) => {
  const [state, setState] = useState<VoiceRecognitionState>({
    status: 'idle',
    transcript: '',
    interimTranscript: '',
    confidence: 0,
    audioLevel: 0,
    error: null,
    isSupported: typeof window !== 'undefined' && 
                 ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)
  });

  const recognitionRef = useRef<any>(null);
  const isActiveRef = useRef(false);
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const retryCountRef = useRef(0);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const lastProcessedTimeRef = useRef<number>(0);
  const lastProcessedTextRef = useRef<string>('');
  const processingFinalRef = useRef(false);

  // Blacklist de palavras de ru√≠do
  const NOISE_WORDS = new Set(['hm', 'ah', 'uh', 'uhm', 'ahn', 'hmm', 'err', 'ehh', '√©h']);

  // Simular n√≠vel de √°udio (em produ√ß√£o, usar Web Audio API real)
  const startAudioLevelMonitoring = useCallback(() => {
    let level = 0;
    const updateLevel = () => {
      if (state.status === 'listening') {
        // Simula√ß√£o de n√≠vel de √°udio vari√°vel
        level = 30 + Math.random() * 60;
      } else {
        level = Math.max(0, level - 5);
      }
      
      setState(prev => ({ ...prev, audioLevel: level }));
      animationFrameRef.current = requestAnimationFrame(updateLevel);
    };
    updateLevel();
  }, [state.status]);

  // Limpar timer de sil√™ncio
  const clearSilenceTimer = useCallback(() => {
    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }
  }, []);

  // Validar se o conte√∫do √© v√°lido (n√£o √© ru√≠do)
  const isValidContent = useCallback((text: string): boolean => {
    const trimmed = text.trim().toLowerCase();
    
    // M√≠nimo de 3 caracteres
    if (trimmed.length < 3) {
      console.log('‚ùå Descartado: muito curto -', text);
      return false;
    }
    
    // Verificar se √© apenas ru√≠do
    const words = trimmed.split(/\s+/);
    const nonNoiseWords = words.filter(w => !NOISE_WORDS.has(w) && w.length > 0);
    
    if (nonNoiseWords.length === 0) {
      console.log('‚ùå Descartado: apenas ru√≠do -', text);
      return false;
    }
    
    // Verificar se tem pelo menos uma palavra com 3+ caracteres
    const hasValidWord = nonNoiseWords.some(w => w.length >= 3);
    if (!hasValidWord) {
      console.log('‚ùå Descartado: sem palavras v√°lidas -', text);
      return false;
    }
    
    return true;
  }, []);

  // Processar resultado final
  const processFinalResult = useCallback((transcript: string, confidence: number) => {
    // Filtro de confian√ßa m√≠nima (60%)
    if (confidence < 0.6) {
      console.log('‚ùå Descartado: confian√ßa baixa -', confidence, transcript);
      return;
    }
    
    // Validar conte√∫do
    if (!isValidContent(transcript)) {
      return;
    }
    
    // Cooldown de 1 segundo entre reconhecimentos
    const now = Date.now();
    if (now - lastProcessedTimeRef.current < 1000) {
      console.log('‚è±Ô∏è Cooldown ativo, ignorando:', transcript);
      return;
    }
    
    // Verificar duplicata
    if (transcript === lastProcessedTextRef.current) {
      console.log('‚ö†Ô∏è Duplicata detectada, ignorando:', transcript);
      return;
    }
    
    console.log('‚úÖ Resultado final v√°lido:', transcript, 'Confian√ßa:', confidence);
    clearSilenceTimer();
    processingFinalRef.current = true;
    lastProcessedTimeRef.current = now;
    lastProcessedTextRef.current = transcript;
    
    setState(prev => ({
      ...prev,
      transcript,
      interimTranscript: '',
      confidence,
      status: 'processing'
    }));

    onResult?.(transcript, confidence);
    
    // Voltar para listening ap√≥s processar
    setTimeout(() => {
      processingFinalRef.current = false;
      setState(prev => prev.status === 'processing' ? { ...prev, status: 'listening' } : prev);
    }, 300);
  }, [clearSilenceTimer, onResult, isValidContent]);

  // Iniciar reconhecimento
  const start = useCallback(() => {
    if (!state.isSupported) {
      setState(prev => ({ 
        ...prev, 
        status: 'unsupported',
        error: 'Reconhecimento de voz n√£o suportado neste navegador' 
      }));
      onError?.('Reconhecimento de voz n√£o suportado');
      return;
    }

    if (isActiveRef.current) {
      console.log('‚ö†Ô∏è Reconhecimento j√° ativo');
      return;
    }

    try {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      
      recognition.continuous = continuous;
      recognition.interimResults = true;
      recognition.lang = language;
      recognition.maxAlternatives = 3;

      recognition.onstart = () => {
        console.log('üé§ Reconhecimento iniciado');
        isActiveRef.current = true;
        retryCountRef.current = 0;
        setState(prev => ({ ...prev, status: 'listening', error: null }));
      };

      recognition.onend = () => {
        console.log('üîá Reconhecimento encerrado');
        isActiveRef.current = false;
        
        // Auto-reconex√£o com backoff exponencial
        if (enabled && retryCountRef.current < 5) {
          const delay = Math.min(300 * Math.pow(2, retryCountRef.current), 5000);
          console.log(`üîÑ Reconectando em ${delay}ms...`);
          setTimeout(() => {
            if (enabled && !isActiveRef.current) {
              retryCountRef.current++;
              start();
            }
          }, delay);
        } else {
          setState(prev => ({ ...prev, status: 'idle' }));
        }
      };

      recognition.onresult = (event: any) => {
        clearSilenceTimer();
        
        let finalTranscript = '';
        let interimTranscript = '';
        let maxConfidence = 0;

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          const confidence = event.results[i][0].confidence || 0.5;
          
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
            maxConfidence = Math.max(maxConfidence, confidence);
          } else {
            interimTranscript += transcript;
          }
        }

        if (finalTranscript.trim()) {
          processFinalResult(finalTranscript.trim(), maxConfidence);
        } else if (interimTranscript.trim() && !processingFinalRef.current) {
          setState(prev => ({ ...prev, interimTranscript: interimTranscript.trim() }));
          
          // Cancelar timer anterior
          clearSilenceTimer();
          
          // Timer de sil√™ncio adaptativo com valida√ß√£o
          silenceTimerRef.current = setTimeout(() => {
            // N√£o processar se j√° houve resultado final recente
            if (processingFinalRef.current) {
              console.log('‚è≠Ô∏è Ignorando interim - resultado final j√° processado');
              return;
            }
            
            const currentInterim = interimTranscript.trim();
            const wordCount = currentInterim.split(' ').filter(w => w.length > 0).length;
            
            // S√≥ processar se tiver conte√∫do significativo (2+ palavras ou 4+ caracteres)
            if (currentInterim && (wordCount >= 2 || currentInterim.length >= 4)) {
              console.log('‚è±Ô∏è Processando por sil√™ncio:', currentInterim);
              processFinalResult(currentInterim, 0.7);
            }
          }, silenceTimeout);
        }
      };

      recognition.onerror = (event: any) => {
        console.error('‚ùå Erro reconhecimento:', event.error);
        isActiveRef.current = false;
        
        let errorMessage = 'Erro desconhecido';
        switch (event.error) {
          case 'not-allowed':
            errorMessage = 'Permiss√£o de microfone negada';
            break;
          case 'no-speech':
            errorMessage = 'Nenhuma fala detectada';
            break;
          case 'audio-capture':
            errorMessage = 'Erro ao capturar √°udio';
            break;
          case 'network':
            errorMessage = 'Erro de rede';
            break;
        }
        
        setState(prev => ({ ...prev, status: 'error', error: errorMessage }));
        onError?.(errorMessage);
        
        // Retry autom√°tico para erros recuper√°veis
        if (['no-speech', 'aborted'].includes(event.error) && enabled && retryCountRef.current < 3) {
          setTimeout(() => {
            if (enabled) {
              retryCountRef.current++;
              start();
            }
          }, 1000);
        }
      };

      recognitionRef.current = recognition;
      recognition.start();
      
    } catch (error) {
      console.error('‚ùå Erro ao iniciar reconhecimento:', error);
      setState(prev => ({ 
        ...prev, 
        status: 'error',
        error: 'Erro ao iniciar reconhecimento de voz'
      }));
      onError?.('Erro ao iniciar reconhecimento de voz');
    }
  }, [state.isSupported, enabled, continuous, language, silenceTimeout, clearSilenceTimer, processFinalResult, onError]);

  // Parar reconhecimento
  const stop = useCallback(() => {
    console.log('üõë Parando reconhecimento');
    clearSilenceTimer();
    
    if (recognitionRef.current && isActiveRef.current) {
      try {
        recognitionRef.current.stop();
        isActiveRef.current = false;
      } catch (error) {
        console.error('Erro ao parar reconhecimento:', error);
      }
    }
    
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }
    
    setState(prev => ({ ...prev, status: 'idle', interimTranscript: '', audioLevel: 0 }));
  }, [clearSilenceTimer]);

  // Reset de erro
  const resetError = useCallback(() => {
    setState(prev => ({ ...prev, status: 'idle', error: null }));
    retryCountRef.current = 0;
  }, []);

  // Refs est√°veis para fun√ß√µes (evitar loop infinito)
  const startRef = useRef(start);
  const stopRef = useRef(stop);
  const startAudioLevelMonitoringRef = useRef(startAudioLevelMonitoring);
  
  // Atualizar refs quando fun√ß√µes mudarem
  useEffect(() => {
    startRef.current = start;
    stopRef.current = stop;
    startAudioLevelMonitoringRef.current = startAudioLevelMonitoring;
  });

  // Ref para rastrear enabled
  const enabledRef = useRef(enabled);
  useEffect(() => {
    enabledRef.current = enabled;
  }, [enabled]);

  // Iniciar/parar baseado em enabled (sem depend√™ncias de fun√ß√µes)
  useEffect(() => {
    if (enabled && state.isSupported) {
      const timer = setTimeout(() => {
        startRef.current();
        startAudioLevelMonitoringRef.current();
      }, 500);
      return () => {
        clearTimeout(timer);
        stopRef.current();
      };
    } else {
      stopRef.current();
    }
  }, [enabled, state.isSupported]);

  // Cleanup
  useEffect(() => {
    return () => {
      stopRef.current();
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, []);

  return {
    ...state,
    start,
    stop,
    resetError
  };
};
